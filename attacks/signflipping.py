# coding: utf-8
###
 # @file   signflipping.py
 # @author John Stephan <john.stephan@epfl.ch>
 #
 # @section LICENSE
 #
 # Copyright © 2018-2021 École Polytechnique Fédérale de Lausanne (EPFL).
 # All rights reserved.
 #
 # @section DESCRIPTION
 #
 # Implementation of the attack introduced in the following paper:
 #   Zeyuan Allen-Zhu, Faeze Ebrahimian, Jerry Li, Dan Alistarh
 #   Byzantine-Resilient Non-Convex Stochastic Gradient Descent
###

import tools

import math
import torch

from . import register

# ---------------------------------------------------------------------------- #
# Attack implementation

def attack(grad_honests, f_real, **kwargs):
  """ Generate the attack gradients.
  Args:
    grad_honests Non-empty list of honest gradients
    f_real       Number of Byzantine gradients to generate
    ...          Ignored keyword-arguments
  Returns:
    Generated Byzantine gradients
  """
  # Fast path
  if f_real == 0:
    return list()
  # Compute the average of honest gradients
  stacked_grads = torch.stack(grad_honests)
  avg_grad = stacked_grads.mean(dim=0)

  # Generate the Byzantine gradient
  byz_grad = avg_grad.mul(-1)
  # Return this Byzantine gradient 'f_real' times
  return [byz_grad] * f_real

def check(grad_honests, f_real, **kwargs):
  """ Check parameter validity for this attack.
  Args:
    grad_honests Non-empty list of honest gradients
    f_real       Number of Byzantine gradients to generate
    ...          Ignored keyword-arguments
  Returns:
    Whether the given parameters are valid for this attack
  """
  if not isinstance(grad_honests, list) or len(grad_honests) == 0:
    return f"Expected a non-empty list of honest gradients, got {grad_honests!r}"
  if not isinstance(f_real, int) or f_real < 0:
    return f"Expected a non-negative number of Byzantine gradients to generate, got {f_real!r}"

# ---------------------------------------------------------------------------- #
# Attack registration

# Register the attack
register("signflipping", attack, check)